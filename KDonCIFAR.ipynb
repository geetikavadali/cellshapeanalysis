{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/geetHonve/RepDistiller.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:02:35.535700Z","iopub.execute_input":"2024-11-30T14:02:35.536024Z","iopub.status.idle":"2024-11-30T14:02:37.195041Z","shell.execute_reply.started":"2024-11-30T14:02:35.535993Z","shell.execute_reply":"2024-11-30T14:02:37.194166Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'RepDistiller'...\nremote: Enumerating objects: 280, done.\u001b[K\nremote: Counting objects: 100% (101/101), done.\u001b[K\nremote: Compressing objects: 100% (43/43), done.\u001b[K\nremote: Total 280 (delta 61), reused 95 (delta 58), pack-reused 179 (from 1)\u001b[K\nReceiving objects: 100% (280/280), 89.30 KiB | 1.94 MiB/s, done.\nResolving deltas: 100% (155/155), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.model_selection import LearningCurveDisplay, ShuffleSplit","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:05:39.752812Z","iopub.execute_input":"2024-11-30T14:05:39.753703Z","iopub.status.idle":"2024-11-30T14:05:40.220485Z","shell.execute_reply.started":"2024-11-30T14:05:39.753668Z","shell.execute_reply":"2024-11-30T14:05:40.219832Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:05:43.577880Z","iopub.execute_input":"2024-11-30T14:05:43.578662Z","iopub.status.idle":"2024-11-30T14:05:52.433710Z","shell.execute_reply.started":"2024-11-30T14:05:43.578627Z","shell.execute_reply":"2024-11-30T14:05:52.432579Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:05:56.572627Z","iopub.execute_input":"2024-11-30T14:05:56.573400Z","iopub.status.idle":"2024-11-30T14:05:59.186908Z","shell.execute_reply.started":"2024-11-30T14:05:56.573363Z","shell.execute_reply":"2024-11-30T14:05:59.186225Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"!pip install TensorRT","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:06:01.398348Z","iopub.execute_input":"2024-11-30T14:06:01.398763Z","iopub.status.idle":"2024-11-30T14:07:36.087586Z","shell.execute_reply.started":"2024-11-30T14:06:01.398734Z","shell.execute_reply":"2024-11-30T14:07:36.086480Z"}},"outputs":[{"name":"stdout","text":"Collecting TensorRT\n  Downloading tensorrt-10.6.0.post1.tar.gz (16 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting tensorrt-cu12==10.6.0.post1 (from TensorRT)\n  Downloading tensorrt-cu12-10.6.0.post1.tar.gz (18 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: TensorRT, tensorrt-cu12\n  Building wheel for TensorRT (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for TensorRT: filename=tensorrt-10.6.0.post1-py2.py3-none-any.whl size=16421 sha256=b6535e888461681033e88437a8e40760211fdc95e189d520ab5a869da11d4a20\n  Stored in directory: /root/.cache/pip/wheels/d6/d4/72/a641e4695bb1b8b57fa2ad1235493c73c469a080b16e5375a9\n  Building wheel for tensorrt-cu12 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for tensorrt-cu12: filename=tensorrt_cu12-10.6.0.post1-py2.py3-none-any.whl size=17630 sha256=a215d30de749fcbb40eecd6e29bf7bd33ee4744fefcfc8ec4fc35aa3efec0d27\n  Stored in directory: /root/.cache/pip/wheels/aa/cb/33/33a230ed5c2a54da56fd68d4edd3adff93b82812124fbf9efd\nSuccessfully built TensorRT tensorrt-cu12\nInstalling collected packages: tensorrt-cu12, TensorRT\nSuccessfully installed TensorRT-10.6.0.post1 tensorrt-cu12-10.6.0.post1\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install tensorboard_logger","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:08:53.162390Z","iopub.execute_input":"2024-11-30T14:08:53.162797Z","iopub.status.idle":"2024-11-30T14:09:01.497850Z","shell.execute_reply.started":"2024-11-30T14:08:53.162721Z","shell.execute_reply":"2024-11-30T14:09:01.496913Z"}},"outputs":[{"name":"stdout","text":"Collecting tensorboard_logger\n  Downloading tensorboard_logger-0.1.0-py2.py3-none-any.whl (17 kB)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from tensorboard_logger) (3.20.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from tensorboard_logger) (1.16.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from tensorboard_logger) (1.23.5)\nRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard_logger) (1.11.2)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard_logger) (9.5.0)\nInstalling collected packages: tensorboard_logger\nSuccessfully installed tensorboard_logger-0.1.0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import tensorflow as tf\nimport datetime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:09:05.834289Z","iopub.execute_input":"2024-11-30T14:09:05.835031Z","iopub.status.idle":"2024-11-30T14:09:13.624070Z","shell.execute_reply.started":"2024-11-30T14:09:05.834994Z","shell.execute_reply":"2024-11-30T14:09:13.623140Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:09:16.526786Z","iopub.execute_input":"2024-11-30T14:09:16.527404Z","iopub.status.idle":"2024-11-30T14:09:16.532568Z","shell.execute_reply.started":"2024-11-30T14:09:16.527369Z","shell.execute_reply":"2024-11-30T14:09:16.531477Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"!sh /kaggle/working/RepDistiller/scripts/fetch_pretrained_teachers.sh","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:09:20.185848Z","iopub.execute_input":"2024-11-30T14:09:20.186876Z","iopub.status.idle":"2024-11-30T14:09:31.739449Z","shell.execute_reply.started":"2024-11-30T14:09:20.186836Z","shell.execute_reply":"2024-11-30T14:09:31.738458Z"}},"outputs":[{"name":"stdout","text":"--2024-11-30 14:09:21--  http://shape2prog.csail.mit.edu/repo/wrn_40_2_vanilla/ckpt_epoch_240.pth\nResolving shape2prog.csail.mit.edu (shape2prog.csail.mit.edu)... 128.52.131.62\nConnecting to shape2prog.csail.mit.edu (shape2prog.csail.mit.edu)|128.52.131.62|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 18113193 (17M)\nSaving to: ‘ckpt_epoch_240.pth’\n\nckpt_epoch_240.pth  100%[===================>]  17.27M  30.3MB/s    in 0.6s    \n\n2024-11-30 14:09:21 (30.3 MB/s) - ‘ckpt_epoch_240.pth’ saved [18113193/18113193]\n\n--2024-11-30 14:09:21--  http://shape2prog.csail.mit.edu/repo/resnet56_vanilla/ckpt_epoch_240.pth\nResolving shape2prog.csail.mit.edu (shape2prog.csail.mit.edu)... 128.52.131.62\nConnecting to shape2prog.csail.mit.edu (shape2prog.csail.mit.edu)|128.52.131.62|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 6981725 (6.7M)\nSaving to: ‘ckpt_epoch_240.pth’\n\nckpt_epoch_240.pth  100%[===================>]   6.66M  17.6MB/s    in 0.4s    \n\n2024-11-30 14:09:22 (17.6 MB/s) - ‘ckpt_epoch_240.pth’ saved [6981725/6981725]\n\n--2024-11-30 14:09:22--  http://shape2prog.csail.mit.edu/repo/resnet110_vanilla/ckpt_epoch_240.pth\nResolving shape2prog.csail.mit.edu (shape2prog.csail.mit.edu)... 128.52.131.62\nConnecting to shape2prog.csail.mit.edu (shape2prog.csail.mit.edu)|128.52.131.62|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 14067163 (13M)\nSaving to: ‘ckpt_epoch_240.pth’\n\nckpt_epoch_240.pth  100%[===================>]  13.42M  26.3MB/s    in 0.5s    \n\n2024-11-30 14:09:23 (26.3 MB/s) - ‘ckpt_epoch_240.pth’ saved [14067163/14067163]\n\n--2024-11-30 14:09:23--  http://shape2prog.csail.mit.edu/repo/resnet32x4_vanilla/ckpt_epoch_240.pth\nResolving shape2prog.csail.mit.edu (shape2prog.csail.mit.edu)... 128.52.131.62\nConnecting to shape2prog.csail.mit.edu (shape2prog.csail.mit.edu)|128.52.131.62|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 59554438 (57M)\nSaving to: ‘ckpt_epoch_240.pth’\n\nckpt_epoch_240.pth  100%[===================>]  56.79M  51.2MB/s    in 1.1s    \n\n2024-11-30 14:09:24 (51.2 MB/s) - ‘ckpt_epoch_240.pth’ saved [59554438/59554438]\n\n--2024-11-30 14:09:24--  http://shape2prog.csail.mit.edu/repo/vgg13_vanilla/ckpt_epoch_240.pth\nResolving shape2prog.csail.mit.edu (shape2prog.csail.mit.edu)... 128.52.131.62\nConnecting to shape2prog.csail.mit.edu (shape2prog.csail.mit.edu)|128.52.131.62|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 75736886 (72M)\nSaving to: ‘ckpt_epoch_240.pth’\n\nckpt_epoch_240.pth  100%[===================>]  72.23M  54.4MB/s    in 1.3s    \n\n2024-11-30 14:09:25 (54.4 MB/s) - ‘ckpt_epoch_240.pth’ saved [75736886/75736886]\n\n--2024-11-30 14:09:25--  http://shape2prog.csail.mit.edu/repo/ResNet50_vanilla/ckpt_epoch_240.pth\nResolving shape2prog.csail.mit.edu (shape2prog.csail.mit.edu)... 128.52.131.62\nConnecting to shape2prog.csail.mit.edu (shape2prog.csail.mit.edu)|128.52.131.62|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 189921718 (181M)\nSaving to: ‘ckpt_epoch_240.pth’\n\nckpt_epoch_240.pth  100%[===================>] 181.12M  35.9MB/s    in 5.4s    \n\n2024-11-30 14:09:31 (33.3 MB/s) - ‘ckpt_epoch_240.pth’ saved [189921718/189921718]\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!python /kaggle/working/RepDistiller/train_student.py --path_t ./save/models/resnet32x4_vanilla/ckpt_epoch_240.pth --distill kd --model_s resnet8x4 -r 0.1 -a 0.9 -b 0 --trial 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:09:44.763579Z","iopub.execute_input":"2024-11-30T14:09:44.764309Z","iopub.status.idle":"2024-11-30T14:32:36.242011Z","shell.execute_reply.started":"2024-11-30T14:09:44.764257Z","shell.execute_reply":"2024-11-30T14:32:36.241047Z"}},"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\nDownloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n100%|███████████████████████| 169001437/169001437 [00:02<00:00, 56512648.29it/s]\nExtracting ./data/cifar-100-python.tar.gz to ./data/\n/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\nFiles already downloaded and verified\n==> loading teacher model\n==> done\nTest: [0/313]\tTime 0.562 (0.562)\tLoss 0.7320 (0.7320)\tAcc@1 81.250 (81.250)\tAcc@5 90.625 (90.625)\nTest: [100/313]\tTime 0.016 (0.021)\tLoss 1.2403 (0.9008)\tAcc@1 68.750 (79.084)\tAcc@5 96.875 (94.554)\nTest: [200/313]\tTime 0.015 (0.018)\tLoss 0.4575 (0.8817)\tAcc@1 81.250 (79.260)\tAcc@5 100.000 (94.527)\nTest: [300/313]\tTime 0.015 (0.017)\tLoss 0.9388 (0.8876)\tAcc@1 71.875 (79.464)\tAcc@5 100.000 (94.581)\n * Acc@1 79.420 Acc@5 94.580\nteacher accuracy:  tensor(79.4200, device='cuda:0')\n==> training...\n/opt/conda/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n  warnings.warn(warning.format(ret))\nEpoch: [1][0/782]\tTime 1.537 (1.537)\tData 0.302 (0.302)\tLoss 10.7907 (10.7907)\tAcc@1 1.562 (1.562)\tAcc@5 3.125 (3.125)\nEpoch: [1][100/782]\tTime 0.045 (0.060)\tData 0.002 (0.005)\tLoss 9.6316 (9.5473)\tAcc@1 7.812 (4.842)\tAcc@5 25.000 (17.497)\nEpoch: [1][200/782]\tTime 0.045 (0.053)\tData 0.002 (0.004)\tLoss 8.6796 (9.3273)\tAcc@1 3.125 (5.822)\tAcc@5 17.188 (21.572)\nEpoch: [1][300/782]\tTime 0.045 (0.051)\tData 0.002 (0.003)\tLoss 7.8271 (9.1814)\tAcc@1 9.375 (6.888)\tAcc@5 32.812 (24.092)\nEpoch: [1][400/782]\tTime 0.046 (0.050)\tData 0.002 (0.003)\tLoss 7.8551 (9.0609)\tAcc@1 15.625 (7.906)\tAcc@5 39.062 (26.379)\nEpoch: [1][500/782]\tTime 0.046 (0.049)\tData 0.002 (0.003)\tLoss 7.3189 (8.9700)\tAcc@1 17.188 (8.608)\tAcc@5 42.188 (28.147)\nEpoch: [1][600/782]\tTime 0.047 (0.049)\tData 0.002 (0.003)\tLoss 7.9260 (8.8835)\tAcc@1 15.625 (9.344)\tAcc@5 45.312 (29.771)\nEpoch: [1][700/782]\tTime 0.047 (0.048)\tData 0.002 (0.003)\tLoss 7.2635 (8.7882)\tAcc@1 15.625 (9.992)\tAcc@5 40.625 (31.335)\n * Acc@1 10.462 Acc@5 32.500\nepoch 1, total time 38.00\nTest: [0/313]\tTime 0.107 (0.107)\tLoss 3.5829 (3.5829)\tAcc@1 9.375 (9.375)\tAcc@5 46.875 (46.875)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 3.5024 (3.7619)\tAcc@1 9.375 (15.192)\tAcc@5 50.000 (42.265)\nTest: [200/313]\tTime 0.005 (0.006)\tLoss 3.3053 (3.7590)\tAcc@1 18.750 (15.065)\tAcc@5 43.750 (42.786)\nTest: [300/313]\tTime 0.005 (0.006)\tLoss 4.4495 (3.7774)\tAcc@1 3.125 (15.044)\tAcc@5 31.250 (42.463)\n * Acc@1 15.330 Acc@5 42.610\nsaving the best model!\n==> training...\nEpoch: [2][0/782]\tTime 0.334 (0.334)\tData 0.288 (0.288)\tLoss 8.0780 (8.0780)\tAcc@1 20.312 (20.312)\tAcc@5 45.312 (45.312)\nEpoch: [2][100/782]\tTime 0.048 (0.050)\tData 0.002 (0.005)\tLoss 8.9933 (8.0465)\tAcc@1 15.625 (16.522)\tAcc@5 46.875 (45.467)\nEpoch: [2][200/782]\tTime 0.047 (0.049)\tData 0.002 (0.004)\tLoss 7.6499 (7.9860)\tAcc@1 28.125 (17.444)\tAcc@5 57.812 (46.471)\nEpoch: [2][300/782]\tTime 0.048 (0.049)\tData 0.002 (0.003)\tLoss 7.8113 (7.9488)\tAcc@1 18.750 (17.899)\tAcc@5 51.562 (47.410)\nEpoch: [2][400/782]\tTime 0.048 (0.049)\tData 0.002 (0.003)\tLoss 7.2698 (7.8252)\tAcc@1 18.750 (18.808)\tAcc@5 48.438 (48.675)\nEpoch: [2][500/782]\tTime 0.049 (0.049)\tData 0.002 (0.003)\tLoss 6.8601 (7.7367)\tAcc@1 18.750 (19.642)\tAcc@5 56.250 (49.819)\nEpoch: [2][600/782]\tTime 0.051 (0.049)\tData 0.003 (0.003)\tLoss 6.9045 (7.6537)\tAcc@1 23.438 (20.222)\tAcc@5 60.938 (50.819)\nEpoch: [2][700/782]\tTime 0.050 (0.049)\tData 0.002 (0.003)\tLoss 6.5824 (7.5805)\tAcc@1 20.312 (21.026)\tAcc@5 53.125 (51.861)\n * Acc@1 21.618 Acc@5 52.632\nepoch 2, total time 38.40\nTest: [0/313]\tTime 0.118 (0.118)\tLoss 4.0483 (4.0483)\tAcc@1 18.750 (18.750)\tAcc@5 56.250 (56.250)\nTest: [100/313]\tTime 0.006 (0.008)\tLoss 3.8952 (3.6128)\tAcc@1 21.875 (23.762)\tAcc@5 50.000 (55.538)\nTest: [200/313]\tTime 0.006 (0.007)\tLoss 2.5471 (3.6661)\tAcc@1 31.250 (22.808)\tAcc@5 68.750 (54.633)\nTest: [300/313]\tTime 0.005 (0.006)\tLoss 4.1702 (3.6741)\tAcc@1 18.750 (22.820)\tAcc@5 53.125 (54.412)\n * Acc@1 23.040 Acc@5 54.560\nsaving the best model!\n==> training...\nEpoch: [3][0/782]\tTime 0.323 (0.323)\tData 0.284 (0.284)\tLoss 7.1478 (7.1478)\tAcc@1 21.875 (21.875)\tAcc@5 53.125 (53.125)\nEpoch: [3][100/782]\tTime 0.051 (0.053)\tData 0.002 (0.005)\tLoss 7.1365 (6.9663)\tAcc@1 31.250 (27.986)\tAcc@5 65.625 (61.804)\nEpoch: [3][200/782]\tTime 0.050 (0.052)\tData 0.002 (0.004)\tLoss 7.4745 (6.8598)\tAcc@1 32.812 (28.700)\tAcc@5 57.812 (62.484)\nEpoch: [3][300/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 7.0797 (6.8246)\tAcc@1 32.812 (28.992)\tAcc@5 67.188 (63.019)\nEpoch: [3][400/782]\tTime 0.052 (0.051)\tData 0.002 (0.003)\tLoss 6.4409 (6.7949)\tAcc@1 40.625 (29.547)\tAcc@5 71.875 (63.474)\nEpoch: [3][500/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 7.1484 (6.7427)\tAcc@1 26.562 (30.056)\tAcc@5 67.188 (64.013)\nEpoch: [3][600/782]\tTime 0.051 (0.051)\tData 0.003 (0.003)\tLoss 6.1111 (6.6923)\tAcc@1 34.375 (30.465)\tAcc@5 68.750 (64.502)\nEpoch: [3][700/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 6.4396 (6.6476)\tAcc@1 28.125 (30.989)\tAcc@5 67.188 (65.119)\n * Acc@1 31.266 Acc@5 65.424\nepoch 3, total time 40.06\nTest: [0/313]\tTime 0.129 (0.129)\tLoss 2.6108 (2.6108)\tAcc@1 50.000 (50.000)\tAcc@5 65.625 (65.625)\nTest: [100/313]\tTime 0.005 (0.007)\tLoss 2.4771 (3.0780)\tAcc@1 37.500 (30.198)\tAcc@5 65.625 (64.047)\nTest: [200/313]\tTime 0.005 (0.006)\tLoss 2.1691 (3.1107)\tAcc@1 50.000 (29.680)\tAcc@5 78.125 (64.412)\nTest: [300/313]\tTime 0.009 (0.006)\tLoss 3.4572 (3.1326)\tAcc@1 31.250 (29.495)\tAcc@5 68.750 (64.358)\n * Acc@1 29.520 Acc@5 64.360\nsaving the best model!\n==> training...\nEpoch: [4][0/782]\tTime 0.316 (0.316)\tData 0.269 (0.269)\tLoss 6.5441 (6.5441)\tAcc@1 25.000 (25.000)\tAcc@5 67.188 (67.188)\nEpoch: [4][100/782]\tTime 0.050 (0.053)\tData 0.002 (0.005)\tLoss 5.8781 (6.3099)\tAcc@1 34.375 (35.458)\tAcc@5 70.312 (69.833)\nEpoch: [4][200/782]\tTime 0.051 (0.052)\tData 0.003 (0.004)\tLoss 6.7224 (6.2410)\tAcc@1 45.312 (36.194)\tAcc@5 79.688 (70.064)\nEpoch: [4][300/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 6.5410 (6.2015)\tAcc@1 28.125 (36.374)\tAcc@5 70.312 (70.562)\nEpoch: [4][400/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 5.5638 (6.1380)\tAcc@1 42.188 (36.748)\tAcc@5 71.875 (71.084)\nEpoch: [4][500/782]\tTime 0.049 (0.051)\tData 0.002 (0.003)\tLoss 5.9918 (6.0999)\tAcc@1 32.812 (37.091)\tAcc@5 70.312 (71.357)\nEpoch: [4][600/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 5.2497 (6.0642)\tAcc@1 51.562 (37.492)\tAcc@5 73.438 (71.802)\nEpoch: [4][700/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 5.7817 (6.0369)\tAcc@1 25.000 (37.721)\tAcc@5 67.188 (72.035)\n * Acc@1 38.052 Acc@5 72.278\nepoch 4, total time 39.70\nTest: [0/313]\tTime 0.113 (0.113)\tLoss 1.7965 (1.7965)\tAcc@1 50.000 (50.000)\tAcc@5 78.125 (78.125)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 2.5348 (2.5358)\tAcc@1 34.375 (38.552)\tAcc@5 75.000 (73.082)\nTest: [200/313]\tTime 0.006 (0.006)\tLoss 1.9368 (2.5538)\tAcc@1 53.125 (37.935)\tAcc@5 75.000 (72.544)\nTest: [300/313]\tTime 0.005 (0.006)\tLoss 2.6362 (2.5631)\tAcc@1 34.375 (37.905)\tAcc@5 68.750 (72.186)\n * Acc@1 37.980 Acc@5 72.170\nsaving the best model!\n==> training...\nEpoch: [5][0/782]\tTime 0.350 (0.350)\tData 0.306 (0.306)\tLoss 5.3338 (5.3338)\tAcc@1 40.625 (40.625)\tAcc@5 78.125 (78.125)\nEpoch: [5][100/782]\tTime 0.050 (0.053)\tData 0.003 (0.005)\tLoss 5.3923 (5.7143)\tAcc@1 40.625 (42.157)\tAcc@5 82.812 (75.897)\nEpoch: [5][200/782]\tTime 0.052 (0.052)\tData 0.002 (0.004)\tLoss 5.7411 (5.6849)\tAcc@1 39.062 (42.071)\tAcc@5 75.000 (75.910)\nEpoch: [5][300/782]\tTime 0.051 (0.052)\tData 0.003 (0.003)\tLoss 5.2590 (5.6724)\tAcc@1 46.875 (42.364)\tAcc@5 78.125 (76.043)\nEpoch: [5][400/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 5.1831 (5.6566)\tAcc@1 43.750 (42.562)\tAcc@5 76.562 (76.212)\nEpoch: [5][500/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.7910 (5.6421)\tAcc@1 43.750 (42.920)\tAcc@5 78.125 (76.519)\nEpoch: [5][600/782]\tTime 0.052 (0.051)\tData 0.002 (0.003)\tLoss 5.6305 (5.6289)\tAcc@1 40.625 (43.022)\tAcc@5 68.750 (76.464)\nEpoch: [5][700/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 5.9886 (5.6120)\tAcc@1 48.438 (43.199)\tAcc@5 70.312 (76.643)\n * Acc@1 43.436 Acc@5 76.796\nepoch 5, total time 39.87\nTest: [0/313]\tTime 0.113 (0.113)\tLoss 2.2303 (2.2303)\tAcc@1 59.375 (59.375)\tAcc@5 78.125 (78.125)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 3.3438 (2.8094)\tAcc@1 40.625 (39.140)\tAcc@5 78.125 (72.525)\nTest: [200/313]\tTime 0.005 (0.006)\tLoss 2.2047 (2.8051)\tAcc@1 40.625 (38.759)\tAcc@5 81.250 (72.559)\nTest: [300/313]\tTime 0.005 (0.006)\tLoss 3.1267 (2.8043)\tAcc@1 25.000 (38.839)\tAcc@5 68.750 (72.394)\n * Acc@1 38.930 Acc@5 72.380\nsaving the best model!\n==> training...\nEpoch: [6][0/782]\tTime 0.418 (0.418)\tData 0.374 (0.374)\tLoss 4.8736 (4.8736)\tAcc@1 37.500 (37.500)\tAcc@5 82.812 (82.812)\nEpoch: [6][100/782]\tTime 0.051 (0.054)\tData 0.002 (0.006)\tLoss 6.1530 (5.4726)\tAcc@1 37.500 (45.761)\tAcc@5 75.000 (77.661)\nEpoch: [6][200/782]\tTime 0.050 (0.052)\tData 0.002 (0.004)\tLoss 5.2844 (5.4334)\tAcc@1 50.000 (46.043)\tAcc@5 81.250 (78.008)\nEpoch: [6][300/782]\tTime 0.051 (0.052)\tData 0.002 (0.003)\tLoss 4.6391 (5.3940)\tAcc@1 54.688 (46.200)\tAcc@5 87.500 (78.369)\nEpoch: [6][400/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.8108 (5.3514)\tAcc@1 45.312 (46.789)\tAcc@5 78.125 (78.900)\nEpoch: [6][500/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 5.0381 (5.3329)\tAcc@1 43.750 (46.881)\tAcc@5 81.250 (79.164)\nEpoch: [6][600/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 5.5733 (5.3166)\tAcc@1 39.062 (47.021)\tAcc@5 82.812 (79.103)\nEpoch: [6][700/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.9764 (5.2989)\tAcc@1 48.438 (46.922)\tAcc@5 81.250 (79.190)\n * Acc@1 47.008 Acc@5 79.302\nepoch 6, total time 39.87\nTest: [0/313]\tTime 0.113 (0.113)\tLoss 1.9174 (1.9174)\tAcc@1 62.500 (62.500)\tAcc@5 75.000 (75.000)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 2.5130 (2.7326)\tAcc@1 53.125 (40.934)\tAcc@5 78.125 (73.762)\nTest: [200/313]\tTime 0.005 (0.006)\tLoss 2.4186 (2.7169)\tAcc@1 50.000 (40.734)\tAcc@5 81.250 (73.585)\nTest: [300/313]\tTime 0.006 (0.006)\tLoss 3.0555 (2.7131)\tAcc@1 28.125 (41.051)\tAcc@5 75.000 (73.733)\n * Acc@1 41.150 Acc@5 73.770\nsaving the best model!\n==> training...\nEpoch: [7][0/782]\tTime 0.364 (0.364)\tData 0.323 (0.323)\tLoss 5.1174 (5.1174)\tAcc@1 51.562 (51.562)\tAcc@5 76.562 (76.562)\nEpoch: [7][100/782]\tTime 0.049 (0.054)\tData 0.002 (0.005)\tLoss 4.8434 (5.1386)\tAcc@1 53.125 (48.762)\tAcc@5 82.812 (81.064)\nEpoch: [7][200/782]\tTime 0.051 (0.052)\tData 0.002 (0.004)\tLoss 4.4758 (5.0979)\tAcc@1 53.125 (49.013)\tAcc@5 81.250 (81.203)\nEpoch: [7][300/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.5669 (5.1018)\tAcc@1 45.312 (49.123)\tAcc@5 84.375 (81.245)\nEpoch: [7][400/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 5.0323 (5.1108)\tAcc@1 43.750 (49.022)\tAcc@5 78.125 (81.063)\nEpoch: [7][500/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 5.2352 (5.1122)\tAcc@1 48.438 (49.080)\tAcc@5 78.125 (81.085)\nEpoch: [7][600/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 5.4957 (5.0966)\tAcc@1 48.438 (49.116)\tAcc@5 78.125 (81.117)\nEpoch: [7][700/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.4621 (5.0836)\tAcc@1 50.000 (49.487)\tAcc@5 87.500 (81.277)\n * Acc@1 49.436 Acc@5 81.356\nepoch 7, total time 39.82\nTest: [0/313]\tTime 0.111 (0.111)\tLoss 2.4893 (2.4893)\tAcc@1 50.000 (50.000)\tAcc@5 78.125 (78.125)\nTest: [100/313]\tTime 0.005 (0.007)\tLoss 2.4981 (2.8765)\tAcc@1 46.875 (41.368)\tAcc@5 78.125 (74.660)\nTest: [200/313]\tTime 0.006 (0.006)\tLoss 1.9938 (2.8420)\tAcc@1 46.875 (41.418)\tAcc@5 84.375 (74.845)\nTest: [300/313]\tTime 0.007 (0.006)\tLoss 3.0897 (2.8271)\tAcc@1 34.375 (41.923)\tAcc@5 71.875 (74.855)\n * Acc@1 42.010 Acc@5 74.900\nsaving the best model!\n==> training...\nEpoch: [8][0/782]\tTime 0.385 (0.385)\tData 0.307 (0.307)\tLoss 5.1210 (5.1210)\tAcc@1 46.875 (46.875)\tAcc@5 76.562 (76.562)\nEpoch: [8][100/782]\tTime 0.050 (0.054)\tData 0.002 (0.005)\tLoss 6.5617 (4.9113)\tAcc@1 40.625 (50.495)\tAcc@5 71.875 (81.977)\nEpoch: [8][200/782]\tTime 0.051 (0.052)\tData 0.003 (0.004)\tLoss 5.9540 (4.8893)\tAcc@1 53.125 (50.847)\tAcc@5 81.250 (82.572)\nEpoch: [8][300/782]\tTime 0.050 (0.052)\tData 0.002 (0.003)\tLoss 5.0611 (4.9054)\tAcc@1 46.875 (51.132)\tAcc@5 78.125 (82.859)\nEpoch: [8][400/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 6.0921 (4.9028)\tAcc@1 56.250 (51.333)\tAcc@5 84.375 (82.766)\nEpoch: [8][500/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 5.0687 (4.8776)\tAcc@1 46.875 (51.506)\tAcc@5 76.562 (82.894)\nEpoch: [8][600/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 5.0917 (4.8708)\tAcc@1 46.875 (51.485)\tAcc@5 78.125 (82.890)\nEpoch: [8][700/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.4769 (4.8753)\tAcc@1 51.562 (51.449)\tAcc@5 84.375 (82.841)\n * Acc@1 51.392 Acc@5 82.856\nepoch 8, total time 39.87\nTest: [0/313]\tTime 0.119 (0.119)\tLoss 1.8897 (1.8897)\tAcc@1 53.125 (53.125)\tAcc@5 71.875 (71.875)\nTest: [100/313]\tTime 0.005 (0.007)\tLoss 2.2683 (2.3354)\tAcc@1 43.750 (45.761)\tAcc@5 84.375 (79.981)\nTest: [200/313]\tTime 0.005 (0.006)\tLoss 1.8891 (2.3827)\tAcc@1 46.875 (45.196)\tAcc@5 75.000 (78.794)\nTest: [300/313]\tTime 0.006 (0.006)\tLoss 2.5513 (2.3529)\tAcc@1 31.250 (45.951)\tAcc@5 62.500 (78.582)\n * Acc@1 45.910 Acc@5 78.600\nsaving the best model!\n==> training...\nEpoch: [9][0/782]\tTime 0.288 (0.288)\tData 0.232 (0.232)\tLoss 4.7400 (4.7400)\tAcc@1 48.438 (48.438)\tAcc@5 82.812 (82.812)\nEpoch: [9][100/782]\tTime 0.050 (0.053)\tData 0.002 (0.005)\tLoss 4.6523 (4.7143)\tAcc@1 51.562 (54.208)\tAcc@5 81.250 (84.499)\nEpoch: [9][200/782]\tTime 0.051 (0.052)\tData 0.002 (0.003)\tLoss 4.4314 (4.7116)\tAcc@1 57.812 (53.887)\tAcc@5 87.500 (84.336)\nEpoch: [9][300/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.7685 (4.7321)\tAcc@1 54.688 (53.987)\tAcc@5 82.812 (84.323)\nEpoch: [9][400/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.6985 (4.7416)\tAcc@1 42.188 (53.932)\tAcc@5 76.562 (84.215)\nEpoch: [9][500/782]\tTime 0.051 (0.051)\tData 0.003 (0.003)\tLoss 4.2513 (4.7438)\tAcc@1 51.562 (53.842)\tAcc@5 79.688 (84.144)\nEpoch: [9][600/782]\tTime 0.050 (0.051)\tData 0.003 (0.003)\tLoss 4.9342 (4.7547)\tAcc@1 46.875 (53.648)\tAcc@5 85.938 (84.001)\nEpoch: [9][700/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.5293 (4.7497)\tAcc@1 50.000 (53.629)\tAcc@5 79.688 (83.965)\n * Acc@1 53.642 Acc@5 83.994\nepoch 9, total time 39.81\nTest: [0/313]\tTime 0.109 (0.109)\tLoss 1.8620 (1.8620)\tAcc@1 56.250 (56.250)\tAcc@5 81.250 (81.250)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 2.0715 (2.3248)\tAcc@1 53.125 (47.958)\tAcc@5 78.125 (79.703)\nTest: [200/313]\tTime 0.006 (0.006)\tLoss 1.6923 (2.3423)\tAcc@1 50.000 (47.341)\tAcc@5 87.500 (79.493)\nTest: [300/313]\tTime 0.005 (0.006)\tLoss 2.6223 (2.3426)\tAcc@1 40.625 (47.747)\tAcc@5 75.000 (79.610)\n * Acc@1 47.640 Acc@5 79.570\nsaving the best model!\n==> training...\nEpoch: [10][0/782]\tTime 0.343 (0.343)\tData 0.296 (0.296)\tLoss 4.9727 (4.9727)\tAcc@1 60.938 (60.938)\tAcc@5 82.812 (82.812)\nEpoch: [10][100/782]\tTime 0.051 (0.053)\tData 0.002 (0.005)\tLoss 4.3462 (4.5098)\tAcc@1 54.688 (55.507)\tAcc@5 85.938 (85.829)\nEpoch: [10][200/782]\tTime 0.050 (0.052)\tData 0.002 (0.004)\tLoss 4.4009 (4.5636)\tAcc@1 60.938 (55.138)\tAcc@5 79.688 (85.316)\nEpoch: [10][300/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 3.9701 (4.5938)\tAcc@1 54.688 (55.144)\tAcc@5 87.500 (85.039)\nEpoch: [10][400/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.6229 (4.5878)\tAcc@1 54.688 (55.210)\tAcc@5 78.125 (84.901)\nEpoch: [10][500/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 5.0807 (4.5996)\tAcc@1 51.562 (55.124)\tAcc@5 85.938 (84.840)\nEpoch: [10][600/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.4131 (4.6107)\tAcc@1 62.500 (55.038)\tAcc@5 87.500 (84.835)\nEpoch: [10][700/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.0956 (4.6122)\tAcc@1 46.875 (54.971)\tAcc@5 87.500 (84.767)\n * Acc@1 55.062 Acc@5 84.816\nepoch 10, total time 39.83\nTest: [0/313]\tTime 0.107 (0.107)\tLoss 1.7351 (1.7351)\tAcc@1 53.125 (53.125)\tAcc@5 81.250 (81.250)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 1.7998 (2.1974)\tAcc@1 53.125 (50.248)\tAcc@5 87.500 (80.538)\nTest: [200/313]\tTime 0.005 (0.006)\tLoss 1.9086 (2.2019)\tAcc@1 56.250 (50.000)\tAcc@5 90.625 (80.644)\nTest: [300/313]\tTime 0.005 (0.006)\tLoss 2.9184 (2.2133)\tAcc@1 34.375 (50.176)\tAcc@5 71.875 (80.399)\n * Acc@1 50.240 Acc@5 80.420\nsaving the best model!\n==> training...\nEpoch: [11][0/782]\tTime 0.342 (0.342)\tData 0.286 (0.286)\tLoss 4.4108 (4.4108)\tAcc@1 57.812 (57.812)\tAcc@5 85.938 (85.938)\nEpoch: [11][100/782]\tTime 0.050 (0.053)\tData 0.003 (0.005)\tLoss 4.7326 (4.5212)\tAcc@1 46.875 (55.554)\tAcc@5 81.250 (85.071)\nEpoch: [11][200/782]\tTime 0.051 (0.052)\tData 0.002 (0.004)\tLoss 4.5346 (4.5257)\tAcc@1 56.250 (55.581)\tAcc@5 90.625 (85.285)\nEpoch: [11][300/782]\tTime 0.050 (0.052)\tData 0.003 (0.003)\tLoss 3.6285 (4.5068)\tAcc@1 60.938 (55.845)\tAcc@5 85.938 (85.610)\nEpoch: [11][400/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 3.5359 (4.5054)\tAcc@1 64.062 (55.895)\tAcc@5 93.750 (85.591)\nEpoch: [11][500/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 3.6044 (4.5283)\tAcc@1 62.500 (55.816)\tAcc@5 87.500 (85.423)\nEpoch: [11][600/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.4733 (4.5213)\tAcc@1 48.438 (55.779)\tAcc@5 81.250 (85.459)\nEpoch: [11][700/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.2169 (4.5197)\tAcc@1 51.562 (55.699)\tAcc@5 90.625 (85.403)\n * Acc@1 55.794 Acc@5 85.510\nepoch 11, total time 39.86\nTest: [0/313]\tTime 0.112 (0.112)\tLoss 2.9116 (2.9116)\tAcc@1 43.750 (43.750)\tAcc@5 68.750 (68.750)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 2.7445 (2.6869)\tAcc@1 34.375 (46.194)\tAcc@5 93.750 (77.259)\nTest: [200/313]\tTime 0.005 (0.006)\tLoss 2.2113 (2.6775)\tAcc@1 50.000 (45.600)\tAcc@5 81.250 (76.384)\nTest: [300/313]\tTime 0.005 (0.006)\tLoss 2.6694 (2.6908)\tAcc@1 40.625 (45.681)\tAcc@5 71.875 (76.526)\n * Acc@1 45.730 Acc@5 76.600\n==> training...\nEpoch: [12][0/782]\tTime 0.320 (0.320)\tData 0.262 (0.262)\tLoss 4.1936 (4.1936)\tAcc@1 54.688 (54.688)\tAcc@5 90.625 (90.625)\nEpoch: [12][100/782]\tTime 0.050 (0.053)\tData 0.002 (0.005)\tLoss 4.8777 (4.4708)\tAcc@1 46.875 (56.776)\tAcc@5 87.500 (86.216)\nEpoch: [12][200/782]\tTime 0.050 (0.052)\tData 0.002 (0.003)\tLoss 4.3321 (4.4405)\tAcc@1 50.000 (57.066)\tAcc@5 90.625 (86.334)\nEpoch: [12][300/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.0857 (4.4504)\tAcc@1 57.812 (56.712)\tAcc@5 89.062 (86.259)\nEpoch: [12][400/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 3.8968 (4.4499)\tAcc@1 59.375 (56.718)\tAcc@5 85.938 (85.961)\nEpoch: [12][500/782]\tTime 0.050 (0.051)\tData 0.003 (0.003)\tLoss 4.1885 (4.4685)\tAcc@1 53.125 (56.549)\tAcc@5 90.625 (85.835)\nEpoch: [12][600/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.5778 (4.4798)\tAcc@1 50.000 (56.619)\tAcc@5 84.375 (85.789)\nEpoch: [12][700/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.2954 (4.4800)\tAcc@1 53.125 (56.665)\tAcc@5 76.562 (85.880)\n * Acc@1 56.600 Acc@5 85.850\nepoch 12, total time 39.81\nTest: [0/313]\tTime 0.116 (0.116)\tLoss 1.9874 (1.9874)\tAcc@1 56.250 (56.250)\tAcc@5 81.250 (81.250)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 2.2681 (2.2175)\tAcc@1 34.375 (51.300)\tAcc@5 87.500 (81.219)\nTest: [200/313]\tTime 0.006 (0.006)\tLoss 1.4358 (2.2085)\tAcc@1 71.875 (51.104)\tAcc@5 90.625 (81.032)\nTest: [300/313]\tTime 0.005 (0.006)\tLoss 2.3749 (2.1956)\tAcc@1 43.750 (51.339)\tAcc@5 75.000 (80.939)\n * Acc@1 51.380 Acc@5 80.910\nsaving the best model!\n==> training...\nEpoch: [13][0/782]\tTime 0.247 (0.247)\tData 0.203 (0.203)\tLoss 3.7378 (3.7378)\tAcc@1 65.625 (65.625)\tAcc@5 92.188 (92.188)\nEpoch: [13][100/782]\tTime 0.050 (0.053)\tData 0.002 (0.004)\tLoss 5.1666 (4.3650)\tAcc@1 51.562 (58.571)\tAcc@5 82.812 (86.974)\nEpoch: [13][200/782]\tTime 0.050 (0.052)\tData 0.002 (0.003)\tLoss 4.4046 (4.3770)\tAcc@1 51.562 (58.396)\tAcc@5 90.625 (86.894)\nEpoch: [13][300/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.5229 (4.3623)\tAcc@1 51.562 (58.186)\tAcc@5 85.938 (87.033)\nEpoch: [13][400/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.3947 (4.3682)\tAcc@1 62.500 (58.023)\tAcc@5 85.938 (86.725)\nEpoch: [13][500/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.5358 (4.3701)\tAcc@1 54.688 (58.081)\tAcc@5 85.938 (86.736)\nEpoch: [13][600/782]\tTime 0.049 (0.051)\tData 0.002 (0.003)\tLoss 4.3245 (4.3760)\tAcc@1 56.250 (57.903)\tAcc@5 82.812 (86.637)\nEpoch: [13][700/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.6414 (4.3858)\tAcc@1 65.625 (57.826)\tAcc@5 81.250 (86.506)\n * Acc@1 57.704 Acc@5 86.336\nepoch 13, total time 39.76\nTest: [0/313]\tTime 0.114 (0.114)\tLoss 1.8804 (1.8804)\tAcc@1 62.500 (62.500)\tAcc@5 75.000 (75.000)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 2.1314 (2.1031)\tAcc@1 50.000 (50.959)\tAcc@5 81.250 (82.209)\nTest: [200/313]\tTime 0.004 (0.006)\tLoss 1.6823 (2.1432)\tAcc@1 65.625 (50.746)\tAcc@5 81.250 (81.701)\nTest: [300/313]\tTime 0.006 (0.006)\tLoss 1.9218 (2.1329)\tAcc@1 53.125 (50.924)\tAcc@5 81.250 (81.613)\n * Acc@1 50.970 Acc@5 81.640\n==> training...\nEpoch: [14][0/782]\tTime 0.296 (0.296)\tData 0.234 (0.234)\tLoss 4.3554 (4.3554)\tAcc@1 51.562 (51.562)\tAcc@5 82.812 (82.812)\nEpoch: [14][100/782]\tTime 0.050 (0.053)\tData 0.002 (0.005)\tLoss 4.7723 (4.2972)\tAcc@1 50.000 (58.926)\tAcc@5 79.688 (86.912)\nEpoch: [14][200/782]\tTime 0.050 (0.052)\tData 0.002 (0.004)\tLoss 4.6050 (4.2832)\tAcc@1 46.875 (59.220)\tAcc@5 85.938 (87.018)\nEpoch: [14][300/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.4842 (4.2884)\tAcc@1 53.125 (58.996)\tAcc@5 89.062 (87.080)\nEpoch: [14][400/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.6266 (4.3002)\tAcc@1 54.688 (58.833)\tAcc@5 85.938 (87.134)\nEpoch: [14][500/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.3926 (4.3092)\tAcc@1 67.188 (58.570)\tAcc@5 89.062 (86.948)\nEpoch: [14][600/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.2426 (4.3096)\tAcc@1 59.375 (58.512)\tAcc@5 85.938 (86.884)\nEpoch: [14][700/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.3252 (4.3155)\tAcc@1 56.250 (58.492)\tAcc@5 84.375 (86.900)\n * Acc@1 58.358 Acc@5 86.868\nepoch 14, total time 39.80\nTest: [0/313]\tTime 0.115 (0.115)\tLoss 2.0554 (2.0554)\tAcc@1 50.000 (50.000)\tAcc@5 78.125 (78.125)\nTest: [100/313]\tTime 0.005 (0.007)\tLoss 2.7331 (2.6931)\tAcc@1 46.875 (45.452)\tAcc@5 78.125 (76.083)\nTest: [200/313]\tTime 0.005 (0.006)\tLoss 1.9804 (2.6657)\tAcc@1 46.875 (45.896)\tAcc@5 81.250 (76.197)\nTest: [300/313]\tTime 0.006 (0.006)\tLoss 2.9185 (2.6443)\tAcc@1 40.625 (46.283)\tAcc@5 71.875 (76.246)\n * Acc@1 46.340 Acc@5 76.310\n==> training...\nEpoch: [15][0/782]\tTime 0.326 (0.326)\tData 0.262 (0.262)\tLoss 4.2536 (4.2536)\tAcc@1 56.250 (56.250)\tAcc@5 87.500 (87.500)\nEpoch: [15][100/782]\tTime 0.051 (0.053)\tData 0.002 (0.005)\tLoss 4.0427 (4.2904)\tAcc@1 64.062 (58.741)\tAcc@5 89.062 (87.206)\nEpoch: [15][200/782]\tTime 0.050 (0.052)\tData 0.002 (0.003)\tLoss 3.8521 (4.2763)\tAcc@1 60.938 (58.947)\tAcc@5 89.062 (87.267)\nEpoch: [15][300/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 3.7331 (4.2647)\tAcc@1 59.375 (59.318)\tAcc@5 85.938 (87.324)\nEpoch: [15][400/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.2905 (4.2681)\tAcc@1 60.938 (59.387)\tAcc@5 89.062 (87.282)\nEpoch: [15][500/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 3.9383 (4.2598)\tAcc@1 65.625 (59.325)\tAcc@5 92.188 (87.250)\nEpoch: [15][600/782]\tTime 0.052 (0.051)\tData 0.002 (0.003)\tLoss 4.4224 (4.2781)\tAcc@1 56.250 (59.206)\tAcc@5 82.812 (87.198)\nEpoch: [15][700/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.6020 (4.2837)\tAcc@1 59.375 (59.072)\tAcc@5 85.938 (87.161)\n * Acc@1 59.080 Acc@5 87.218\nepoch 15, total time 39.81\nTest: [0/313]\tTime 0.110 (0.110)\tLoss 1.7654 (1.7654)\tAcc@1 65.625 (65.625)\tAcc@5 78.125 (78.125)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 2.0055 (2.0942)\tAcc@1 50.000 (51.702)\tAcc@5 78.125 (80.786)\nTest: [200/313]\tTime 0.005 (0.006)\tLoss 1.8087 (2.1170)\tAcc@1 50.000 (51.679)\tAcc@5 81.250 (80.675)\nTest: [300/313]\tTime 0.005 (0.006)\tLoss 1.7019 (2.1213)\tAcc@1 56.250 (51.682)\tAcc@5 87.500 (80.669)\n * Acc@1 51.600 Acc@5 80.640\nsaving the best model!\n==> training...\nEpoch: [16][0/782]\tTime 0.279 (0.279)\tData 0.206 (0.206)\tLoss 4.3290 (4.3290)\tAcc@1 56.250 (56.250)\tAcc@5 89.062 (89.062)\nEpoch: [16][100/782]\tTime 0.050 (0.053)\tData 0.002 (0.004)\tLoss 4.5147 (4.1535)\tAcc@1 59.375 (60.319)\tAcc@5 84.375 (88.165)\nEpoch: [16][200/782]\tTime 0.051 (0.052)\tData 0.002 (0.003)\tLoss 4.6756 (4.1225)\tAcc@1 51.562 (60.813)\tAcc@5 82.812 (88.200)\nEpoch: [16][300/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.3894 (4.1722)\tAcc@1 56.250 (60.200)\tAcc@5 87.500 (87.905)\nEpoch: [16][400/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.2220 (4.1830)\tAcc@1 62.500 (60.170)\tAcc@5 93.750 (87.827)\nEpoch: [16][500/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.4901 (4.2016)\tAcc@1 59.375 (59.821)\tAcc@5 85.938 (87.640)\nEpoch: [16][600/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.7153 (4.2157)\tAcc@1 53.125 (59.700)\tAcc@5 85.938 (87.505)\nEpoch: [16][700/782]\tTime 0.051 (0.051)\tData 0.002 (0.002)\tLoss 4.1905 (4.2236)\tAcc@1 56.250 (59.524)\tAcc@5 85.938 (87.507)\n * Acc@1 59.360 Acc@5 87.486\nepoch 16, total time 39.74\nTest: [0/313]\tTime 0.109 (0.109)\tLoss 1.7093 (1.7093)\tAcc@1 71.875 (71.875)\tAcc@5 81.250 (81.250)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 2.6284 (2.2216)\tAcc@1 43.750 (51.887)\tAcc@5 75.000 (81.188)\nTest: [200/313]\tTime 0.005 (0.006)\tLoss 1.9488 (2.2006)\tAcc@1 53.125 (52.006)\tAcc@5 87.500 (81.390)\nTest: [300/313]\tTime 0.005 (0.006)\tLoss 2.1704 (2.2098)\tAcc@1 50.000 (52.076)\tAcc@5 78.125 (81.188)\n * Acc@1 52.140 Acc@5 81.240\nsaving the best model!\n==> training...\nEpoch: [17][0/782]\tTime 0.257 (0.257)\tData 0.202 (0.202)\tLoss 4.3184 (4.3184)\tAcc@1 60.938 (60.938)\tAcc@5 84.375 (84.375)\nEpoch: [17][100/782]\tTime 0.049 (0.053)\tData 0.003 (0.004)\tLoss 4.4877 (4.1511)\tAcc@1 51.562 (61.077)\tAcc@5 87.500 (87.902)\nEpoch: [17][200/782]\tTime 0.050 (0.052)\tData 0.002 (0.003)\tLoss 3.9849 (4.1903)\tAcc@1 56.250 (60.238)\tAcc@5 92.188 (87.873)\nEpoch: [17][300/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 3.9454 (4.2047)\tAcc@1 70.312 (59.837)\tAcc@5 93.750 (87.578)\nEpoch: [17][400/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.1061 (4.1923)\tAcc@1 60.938 (59.932)\tAcc@5 90.625 (87.675)\nEpoch: [17][500/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.7512 (4.1952)\tAcc@1 57.812 (60.017)\tAcc@5 82.812 (87.706)\nEpoch: [17][600/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.7565 (4.2054)\tAcc@1 50.000 (59.783)\tAcc@5 82.812 (87.648)\nEpoch: [17][700/782]\tTime 0.050 (0.051)\tData 0.002 (0.002)\tLoss 4.1287 (4.2187)\tAcc@1 59.375 (59.761)\tAcc@5 82.812 (87.663)\n * Acc@1 59.644 Acc@5 87.634\nepoch 17, total time 39.79\nTest: [0/313]\tTime 0.109 (0.109)\tLoss 1.9989 (1.9989)\tAcc@1 56.250 (56.250)\tAcc@5 78.125 (78.125)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 2.6786 (2.2326)\tAcc@1 40.625 (50.588)\tAcc@5 71.875 (81.652)\nTest: [200/313]\tTime 0.005 (0.006)\tLoss 2.0961 (2.2421)\tAcc@1 50.000 (51.104)\tAcc@5 81.250 (81.359)\nTest: [300/313]\tTime 0.005 (0.006)\tLoss 2.2080 (2.2178)\tAcc@1 43.750 (51.339)\tAcc@5 84.375 (81.406)\n * Acc@1 51.420 Acc@5 81.410\n==> training...\nEpoch: [18][0/782]\tTime 0.282 (0.282)\tData 0.218 (0.218)\tLoss 3.9696 (3.9696)\tAcc@1 65.625 (65.625)\tAcc@5 90.625 (90.625)\nEpoch: [18][100/782]\tTime 0.050 (0.053)\tData 0.002 (0.005)\tLoss 3.6424 (4.0864)\tAcc@1 67.188 (61.510)\tAcc@5 92.188 (88.800)\nEpoch: [18][200/782]\tTime 0.050 (0.052)\tData 0.002 (0.003)\tLoss 3.5185 (4.1196)\tAcc@1 67.188 (60.883)\tAcc@5 90.625 (88.153)\nEpoch: [18][300/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.2965 (4.1425)\tAcc@1 54.688 (60.953)\tAcc@5 82.812 (88.222)\nEpoch: [18][400/782]\tTime 0.049 (0.051)\tData 0.002 (0.003)\tLoss 4.3610 (4.1605)\tAcc@1 59.375 (60.634)\tAcc@5 87.500 (88.209)\nEpoch: [18][500/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.5691 (4.1619)\tAcc@1 46.875 (60.569)\tAcc@5 84.375 (88.036)\nEpoch: [18][600/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 3.7020 (4.1620)\tAcc@1 70.312 (60.628)\tAcc@5 95.312 (87.999)\nEpoch: [18][700/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.6199 (4.1719)\tAcc@1 59.375 (60.322)\tAcc@5 84.375 (87.830)\n * Acc@1 60.248 Acc@5 87.786\nepoch 18, total time 39.80\nTest: [0/313]\tTime 0.117 (0.117)\tLoss 3.8845 (3.8845)\tAcc@1 40.625 (40.625)\tAcc@5 75.000 (75.000)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 4.1261 (3.2380)\tAcc@1 37.500 (43.502)\tAcc@5 75.000 (77.042)\nTest: [200/313]\tTime 0.005 (0.006)\tLoss 2.5700 (3.2752)\tAcc@1 50.000 (42.988)\tAcc@5 84.375 (76.430)\nTest: [300/313]\tTime 0.005 (0.006)\tLoss 3.5394 (3.2482)\tAcc@1 43.750 (43.137)\tAcc@5 65.625 (76.806)\n * Acc@1 43.290 Acc@5 76.780\n==> training...\nEpoch: [19][0/782]\tTime 0.334 (0.334)\tData 0.275 (0.275)\tLoss 3.6075 (3.6075)\tAcc@1 65.625 (65.625)\tAcc@5 87.500 (87.500)\nEpoch: [19][100/782]\tTime 0.051 (0.053)\tData 0.002 (0.005)\tLoss 3.7777 (4.1103)\tAcc@1 64.062 (60.381)\tAcc@5 93.750 (88.289)\nEpoch: [19][200/782]\tTime 0.050 (0.052)\tData 0.002 (0.003)\tLoss 3.8970 (4.1095)\tAcc@1 60.938 (60.269)\tAcc@5 92.188 (88.192)\nEpoch: [19][300/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 3.7740 (4.1344)\tAcc@1 65.625 (60.543)\tAcc@5 84.375 (88.196)\nEpoch: [19][400/782]\tTime 0.049 (0.051)\tData 0.002 (0.003)\tLoss 3.9291 (4.1491)\tAcc@1 56.250 (60.614)\tAcc@5 87.500 (88.042)\nEpoch: [19][500/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 3.8000 (4.1487)\tAcc@1 67.188 (60.601)\tAcc@5 90.625 (88.061)\nEpoch: [19][600/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 3.6215 (4.1493)\tAcc@1 59.375 (60.561)\tAcc@5 84.375 (88.106)\nEpoch: [19][700/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.3576 (4.1383)\tAcc@1 57.812 (60.690)\tAcc@5 92.188 (88.178)\n * Acc@1 60.612 Acc@5 88.122\nepoch 19, total time 39.85\nTest: [0/313]\tTime 0.116 (0.116)\tLoss 1.5697 (1.5697)\tAcc@1 59.375 (59.375)\tAcc@5 81.250 (81.250)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 1.7215 (1.9493)\tAcc@1 53.125 (55.167)\tAcc@5 87.500 (84.035)\nTest: [200/313]\tTime 0.005 (0.006)\tLoss 1.9607 (1.9571)\tAcc@1 46.875 (54.586)\tAcc@5 84.375 (84.111)\nTest: [300/313]\tTime 0.006 (0.006)\tLoss 2.6547 (1.9759)\tAcc@1 31.250 (54.340)\tAcc@5 84.375 (83.617)\n * Acc@1 54.550 Acc@5 83.680\nsaving the best model!\n==> training...\nEpoch: [20][0/782]\tTime 0.320 (0.320)\tData 0.239 (0.239)\tLoss 4.2154 (4.2154)\tAcc@1 56.250 (56.250)\tAcc@5 92.188 (92.188)\nEpoch: [20][100/782]\tTime 0.050 (0.053)\tData 0.002 (0.005)\tLoss 4.4151 (4.0726)\tAcc@1 54.688 (61.556)\tAcc@5 90.625 (88.691)\nEpoch: [20][200/782]\tTime 0.051 (0.052)\tData 0.002 (0.003)\tLoss 4.2454 (4.1030)\tAcc@1 62.500 (61.124)\tAcc@5 92.188 (88.713)\nEpoch: [20][300/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.6493 (4.0958)\tAcc@1 59.375 (61.171)\tAcc@5 89.062 (88.585)\nEpoch: [20][400/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.3076 (4.1066)\tAcc@1 59.375 (61.109)\tAcc@5 85.938 (88.540)\nEpoch: [20][500/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.4511 (4.1071)\tAcc@1 60.938 (60.850)\tAcc@5 89.062 (88.414)\nEpoch: [20][600/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.0755 (4.1188)\tAcc@1 59.375 (60.815)\tAcc@5 87.500 (88.428)\nEpoch: [20][700/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.0539 (4.1194)\tAcc@1 60.938 (60.677)\tAcc@5 82.812 (88.383)\n * Acc@1 60.628 Acc@5 88.372\nepoch 20, total time 39.82\nTest: [0/313]\tTime 0.114 (0.114)\tLoss 2.0366 (2.0366)\tAcc@1 65.625 (65.625)\tAcc@5 81.250 (81.250)\nTest: [100/313]\tTime 0.005 (0.007)\tLoss 2.3108 (2.1293)\tAcc@1 43.750 (52.073)\tAcc@5 93.750 (82.116)\nTest: [200/313]\tTime 0.005 (0.006)\tLoss 2.4171 (2.1415)\tAcc@1 50.000 (51.835)\tAcc@5 78.125 (82.058)\nTest: [300/313]\tTime 0.005 (0.006)\tLoss 2.0566 (2.1372)\tAcc@1 46.875 (52.222)\tAcc@5 84.375 (81.842)\n * Acc@1 52.320 Acc@5 81.940\n==> training...\nEpoch: [21][0/782]\tTime 0.286 (0.286)\tData 0.204 (0.204)\tLoss 4.7673 (4.7673)\tAcc@1 46.875 (46.875)\tAcc@5 84.375 (84.375)\nEpoch: [21][100/782]\tTime 0.051 (0.053)\tData 0.002 (0.004)\tLoss 4.1937 (4.0540)\tAcc@1 65.625 (61.943)\tAcc@5 92.188 (88.552)\nEpoch: [21][200/782]\tTime 0.051 (0.052)\tData 0.002 (0.003)\tLoss 4.2021 (4.0703)\tAcc@1 67.188 (61.575)\tAcc@5 90.625 (88.456)\nEpoch: [21][300/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 3.6870 (4.0777)\tAcc@1 62.500 (61.270)\tAcc@5 90.625 (88.507)\nEpoch: [21][400/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.3456 (4.0762)\tAcc@1 59.375 (61.230)\tAcc@5 90.625 (88.361)\nEpoch: [21][500/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.1097 (4.0789)\tAcc@1 56.250 (60.994)\tAcc@5 89.062 (88.373)\nEpoch: [21][600/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.2184 (4.0908)\tAcc@1 57.812 (60.805)\tAcc@5 87.500 (88.397)\nEpoch: [21][700/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.0232 (4.1031)\tAcc@1 62.500 (60.703)\tAcc@5 90.625 (88.320)\n * Acc@1 60.660 Acc@5 88.334\nepoch 21, total time 39.76\nTest: [0/313]\tTime 0.122 (0.122)\tLoss 2.1371 (2.1371)\tAcc@1 53.125 (53.125)\tAcc@5 71.875 (71.875)\nTest: [100/313]\tTime 0.008 (0.007)\tLoss 2.0630 (2.3300)\tAcc@1 50.000 (49.196)\tAcc@5 84.375 (79.301)\nTest: [200/313]\tTime 0.005 (0.007)\tLoss 2.1383 (2.3363)\tAcc@1 46.875 (49.207)\tAcc@5 81.250 (78.871)\nTest: [300/313]\tTime 0.005 (0.007)\tLoss 2.5010 (2.3076)\tAcc@1 43.750 (49.626)\tAcc@5 78.125 (79.288)\n * Acc@1 49.820 Acc@5 79.370\n==> training...\nEpoch: [22][0/782]\tTime 0.391 (0.391)\tData 0.333 (0.333)\tLoss 4.1243 (4.1243)\tAcc@1 70.312 (70.312)\tAcc@5 85.938 (85.938)\nEpoch: [22][100/782]\tTime 0.051 (0.054)\tData 0.002 (0.005)\tLoss 3.8579 (4.0670)\tAcc@1 62.500 (61.850)\tAcc@5 87.500 (89.124)\nEpoch: [22][200/782]\tTime 0.052 (0.052)\tData 0.002 (0.004)\tLoss 3.8646 (4.0662)\tAcc@1 57.812 (61.451)\tAcc@5 82.812 (88.355)\nEpoch: [22][300/782]\tTime 0.051 (0.052)\tData 0.002 (0.003)\tLoss 4.4181 (4.0526)\tAcc@1 62.500 (61.540)\tAcc@5 93.750 (88.528)\nEpoch: [22][400/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.5454 (4.0515)\tAcc@1 56.250 (61.651)\tAcc@5 87.500 (88.552)\nEpoch: [22][500/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.9961 (4.0618)\tAcc@1 53.125 (61.611)\tAcc@5 84.375 (88.445)\nEpoch: [22][600/782]\tTime 0.052 (0.051)\tData 0.002 (0.003)\tLoss 4.9523 (4.0681)\tAcc@1 48.438 (61.470)\tAcc@5 78.125 (88.366)\nEpoch: [22][700/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.2188 (4.0793)\tAcc@1 57.812 (61.365)\tAcc@5 85.938 (88.360)\n * Acc@1 61.350 Acc@5 88.398\nepoch 22, total time 39.80\nTest: [0/313]\tTime 0.108 (0.108)\tLoss 3.1352 (3.1352)\tAcc@1 56.250 (56.250)\tAcc@5 84.375 (84.375)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 4.4450 (2.5562)\tAcc@1 34.375 (49.629)\tAcc@5 75.000 (81.869)\nTest: [200/313]\tTime 0.007 (0.006)\tLoss 2.4596 (2.5415)\tAcc@1 53.125 (49.534)\tAcc@5 87.500 (81.592)\nTest: [300/313]\tTime 0.005 (0.006)\tLoss 2.5258 (2.5200)\tAcc@1 53.125 (50.125)\tAcc@5 81.250 (81.510)\n * Acc@1 50.270 Acc@5 81.500\n==> training...\nEpoch: [23][0/782]\tTime 0.245 (0.245)\tData 0.198 (0.198)\tLoss 3.4389 (3.4389)\tAcc@1 62.500 (62.500)\tAcc@5 92.188 (92.188)\nEpoch: [23][100/782]\tTime 0.050 (0.053)\tData 0.002 (0.004)\tLoss 3.8947 (4.0108)\tAcc@1 65.625 (63.181)\tAcc@5 85.938 (89.001)\nEpoch: [23][200/782]\tTime 0.051 (0.052)\tData 0.002 (0.003)\tLoss 3.8430 (4.0181)\tAcc@1 56.250 (62.539)\tAcc@5 87.500 (88.720)\nEpoch: [23][300/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 3.7585 (4.0606)\tAcc@1 59.375 (61.727)\tAcc@5 81.250 (88.637)\nEpoch: [23][400/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 3.3455 (4.0651)\tAcc@1 60.938 (61.588)\tAcc@5 84.375 (88.552)\nEpoch: [23][500/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 3.5245 (4.0734)\tAcc@1 59.375 (61.468)\tAcc@5 87.500 (88.542)\nEpoch: [23][600/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.2859 (4.0738)\tAcc@1 60.938 (61.434)\tAcc@5 85.938 (88.491)\nEpoch: [23][700/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 3.7019 (4.0666)\tAcc@1 82.812 (61.330)\tAcc@5 96.875 (88.447)\n * Acc@1 61.250 Acc@5 88.472\nepoch 23, total time 39.78\nTest: [0/313]\tTime 0.106 (0.106)\tLoss 1.6868 (1.6868)\tAcc@1 56.250 (56.250)\tAcc@5 87.500 (87.500)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 2.6676 (2.7135)\tAcc@1 40.625 (45.885)\tAcc@5 84.375 (78.156)\nTest: [200/313]\tTime 0.008 (0.006)\tLoss 2.1206 (2.6809)\tAcc@1 56.250 (46.486)\tAcc@5 81.250 (78.389)\nTest: [300/313]\tTime 0.007 (0.006)\tLoss 2.8268 (2.6930)\tAcc@1 50.000 (46.480)\tAcc@5 71.875 (78.167)\n * Acc@1 46.520 Acc@5 78.260\n==> training...\nEpoch: [24][0/782]\tTime 0.343 (0.343)\tData 0.291 (0.291)\tLoss 3.5822 (3.5822)\tAcc@1 62.500 (62.500)\tAcc@5 84.375 (84.375)\nEpoch: [24][100/782]\tTime 0.051 (0.053)\tData 0.002 (0.005)\tLoss 3.0497 (3.9589)\tAcc@1 65.625 (61.696)\tAcc@5 93.750 (88.707)\nEpoch: [24][200/782]\tTime 0.051 (0.052)\tData 0.002 (0.004)\tLoss 4.1020 (4.0134)\tAcc@1 65.625 (61.163)\tAcc@5 92.188 (88.565)\nEpoch: [24][300/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.6651 (4.0153)\tAcc@1 57.812 (61.727)\tAcc@5 81.250 (88.538)\nEpoch: [24][400/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.2594 (4.0120)\tAcc@1 57.812 (61.709)\tAcc@5 87.500 (88.447)\nEpoch: [24][500/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.1839 (4.0185)\tAcc@1 60.938 (61.636)\tAcc@5 85.938 (88.579)\nEpoch: [24][600/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 3.7110 (4.0324)\tAcc@1 67.188 (61.585)\tAcc@5 87.500 (88.532)\nEpoch: [24][700/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.9959 (4.0331)\tAcc@1 43.750 (61.468)\tAcc@5 75.000 (88.588)\n * Acc@1 61.442 Acc@5 88.458\nepoch 24, total time 39.80\nTest: [0/313]\tTime 0.109 (0.109)\tLoss 3.8418 (3.8418)\tAcc@1 50.000 (50.000)\tAcc@5 78.125 (78.125)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 3.4216 (2.9442)\tAcc@1 43.750 (45.421)\tAcc@5 81.250 (79.332)\nTest: [200/313]\tTime 0.005 (0.006)\tLoss 2.2728 (2.9529)\tAcc@1 53.125 (45.072)\tAcc@5 81.250 (78.856)\nTest: [300/313]\tTime 0.005 (0.006)\tLoss 3.1027 (2.9330)\tAcc@1 34.375 (45.359)\tAcc@5 87.500 (78.613)\n * Acc@1 45.450 Acc@5 78.580\n==> training...\nEpoch: [25][0/782]\tTime 0.300 (0.300)\tData 0.240 (0.240)\tLoss 3.7106 (3.7106)\tAcc@1 65.625 (65.625)\tAcc@5 87.500 (87.500)\nEpoch: [25][100/782]\tTime 0.050 (0.053)\tData 0.002 (0.004)\tLoss 4.8039 (3.8980)\tAcc@1 60.938 (63.537)\tAcc@5 87.500 (89.279)\nEpoch: [25][200/782]\tTime 0.051 (0.052)\tData 0.003 (0.003)\tLoss 3.8361 (3.9568)\tAcc@1 67.188 (62.718)\tAcc@5 93.750 (89.257)\nEpoch: [25][300/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 3.5636 (3.9630)\tAcc@1 64.062 (62.599)\tAcc@5 89.062 (89.286)\nEpoch: [25][400/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.3523 (3.9633)\tAcc@1 57.812 (62.551)\tAcc@5 92.188 (89.257)\nEpoch: [25][500/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.5936 (3.9822)\tAcc@1 54.688 (62.244)\tAcc@5 82.812 (89.084)\nEpoch: [25][600/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 3.7293 (3.9947)\tAcc@1 65.625 (62.178)\tAcc@5 85.938 (88.995)\nEpoch: [25][700/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.0806 (4.0020)\tAcc@1 60.938 (62.083)\tAcc@5 90.625 (88.871)\n * Acc@1 62.036 Acc@5 88.820\nepoch 25, total time 39.73\nTest: [0/313]\tTime 0.114 (0.114)\tLoss 1.5677 (1.5677)\tAcc@1 62.500 (62.500)\tAcc@5 87.500 (87.500)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 1.9111 (2.0535)\tAcc@1 56.250 (53.713)\tAcc@5 87.500 (82.426)\nTest: [200/313]\tTime 0.005 (0.006)\tLoss 1.7894 (2.0590)\tAcc@1 56.250 (53.591)\tAcc@5 90.625 (82.789)\nTest: [300/313]\tTime 0.005 (0.006)\tLoss 2.6602 (2.0658)\tAcc@1 46.875 (53.727)\tAcc@5 78.125 (82.849)\n * Acc@1 53.720 Acc@5 82.850\n==> training...\nEpoch: [26][0/782]\tTime 0.333 (0.333)\tData 0.286 (0.286)\tLoss 3.4355 (3.4355)\tAcc@1 68.750 (68.750)\tAcc@5 93.750 (93.750)\nEpoch: [26][100/782]\tTime 0.051 (0.053)\tData 0.002 (0.005)\tLoss 3.8065 (3.9062)\tAcc@1 54.688 (63.366)\tAcc@5 87.500 (89.341)\nEpoch: [26][200/782]\tTime 0.049 (0.052)\tData 0.002 (0.004)\tLoss 4.3433 (3.9285)\tAcc@1 51.562 (63.262)\tAcc@5 87.500 (89.350)\nEpoch: [26][300/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.1687 (3.9634)\tAcc@1 60.938 (62.879)\tAcc@5 87.500 (89.172)\nEpoch: [26][400/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.1525 (3.9976)\tAcc@1 59.375 (62.360)\tAcc@5 89.062 (88.875)\nEpoch: [26][500/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.7317 (3.9957)\tAcc@1 51.562 (62.135)\tAcc@5 84.375 (88.688)\nEpoch: [26][600/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.1596 (4.0125)\tAcc@1 54.688 (61.788)\tAcc@5 85.938 (88.540)\nEpoch: [26][700/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 3.9578 (4.0172)\tAcc@1 48.438 (61.742)\tAcc@5 89.062 (88.512)\n * Acc@1 61.922 Acc@5 88.552\nepoch 26, total time 39.82\nTest: [0/313]\tTime 0.112 (0.112)\tLoss 1.9433 (1.9433)\tAcc@1 68.750 (68.750)\tAcc@5 84.375 (84.375)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 2.1502 (2.2640)\tAcc@1 56.250 (52.073)\tAcc@5 81.250 (80.538)\nTest: [200/313]\tTime 0.006 (0.006)\tLoss 2.2703 (2.2423)\tAcc@1 53.125 (51.881)\tAcc@5 87.500 (80.675)\nTest: [300/313]\tTime 0.005 (0.006)\tLoss 2.6547 (2.2171)\tAcc@1 40.625 (52.336)\tAcc@5 71.875 (80.866)\n * Acc@1 52.340 Acc@5 80.900\n==> training...\nEpoch: [27][0/782]\tTime 0.249 (0.249)\tData 0.204 (0.204)\tLoss 4.0314 (4.0314)\tAcc@1 57.812 (57.812)\tAcc@5 90.625 (90.625)\nEpoch: [27][100/782]\tTime 0.052 (0.053)\tData 0.002 (0.004)\tLoss 3.9111 (3.9495)\tAcc@1 56.250 (62.670)\tAcc@5 89.062 (89.217)\nEpoch: [27][200/782]\tTime 0.050 (0.052)\tData 0.002 (0.003)\tLoss 3.6343 (3.9381)\tAcc@1 70.312 (63.021)\tAcc@5 96.875 (89.171)\nEpoch: [27][300/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.2558 (3.9412)\tAcc@1 62.500 (63.284)\tAcc@5 90.625 (89.218)\nEpoch: [27][400/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 3.3720 (3.9576)\tAcc@1 64.062 (62.773)\tAcc@5 93.750 (89.043)\nEpoch: [27][500/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.5820 (3.9740)\tAcc@1 51.562 (62.603)\tAcc@5 82.812 (88.919)\nEpoch: [27][600/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.0773 (3.9899)\tAcc@1 59.375 (62.352)\tAcc@5 81.250 (88.907)\nEpoch: [27][700/782]\tTime 0.050 (0.051)\tData 0.002 (0.002)\tLoss 3.4425 (3.9953)\tAcc@1 53.125 (62.083)\tAcc@5 87.500 (88.840)\n * Acc@1 62.120 Acc@5 88.800\nepoch 27, total time 39.78\nTest: [0/313]\tTime 0.116 (0.116)\tLoss 1.5220 (1.5220)\tAcc@1 62.500 (62.500)\tAcc@5 87.500 (87.500)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 2.1443 (2.1600)\tAcc@1 53.125 (52.661)\tAcc@5 90.625 (81.869)\nTest: [200/313]\tTime 0.005 (0.006)\tLoss 2.2685 (2.1247)\tAcc@1 40.625 (52.519)\tAcc@5 81.250 (81.872)\nTest: [300/313]\tTime 0.005 (0.006)\tLoss 2.8763 (2.1378)\tAcc@1 31.250 (52.606)\tAcc@5 78.125 (81.966)\n * Acc@1 52.760 Acc@5 81.980\n==> training...\nEpoch: [28][0/782]\tTime 0.291 (0.291)\tData 0.247 (0.247)\tLoss 3.2377 (3.2377)\tAcc@1 73.438 (73.438)\tAcc@5 84.375 (84.375)\nEpoch: [28][100/782]\tTime 0.052 (0.053)\tData 0.002 (0.005)\tLoss 3.7970 (4.0406)\tAcc@1 65.625 (63.382)\tAcc@5 89.062 (89.434)\nEpoch: [28][200/782]\tTime 0.050 (0.052)\tData 0.002 (0.004)\tLoss 3.9949 (4.0066)\tAcc@1 62.500 (63.099)\tAcc@5 85.938 (89.202)\nEpoch: [28][300/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.0274 (4.0057)\tAcc@1 62.500 (62.827)\tAcc@5 92.188 (89.182)\nEpoch: [28][400/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 3.9678 (3.9833)\tAcc@1 60.938 (62.594)\tAcc@5 90.625 (89.195)\nEpoch: [28][500/782]\tTime 0.051 (0.051)\tData 0.003 (0.003)\tLoss 4.2480 (3.9871)\tAcc@1 57.812 (62.441)\tAcc@5 89.062 (89.172)\nEpoch: [28][600/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 3.7713 (3.9840)\tAcc@1 59.375 (62.529)\tAcc@5 89.062 (89.094)\nEpoch: [28][700/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.6574 (3.9755)\tAcc@1 62.500 (62.400)\tAcc@5 84.375 (89.062)\n * Acc@1 62.312 Acc@5 89.014\nepoch 28, total time 39.82\nTest: [0/313]\tTime 0.110 (0.110)\tLoss 1.7197 (1.7197)\tAcc@1 71.875 (71.875)\tAcc@5 81.250 (81.250)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 2.2164 (2.1227)\tAcc@1 53.125 (54.610)\tAcc@5 87.500 (82.302)\nTest: [200/313]\tTime 0.005 (0.006)\tLoss 1.9841 (2.1126)\tAcc@1 62.500 (54.680)\tAcc@5 81.250 (82.167)\nTest: [300/313]\tTime 0.005 (0.006)\tLoss 2.4169 (2.1075)\tAcc@1 50.000 (55.056)\tAcc@5 84.375 (82.465)\n * Acc@1 55.040 Acc@5 82.410\nsaving the best model!\n==> training...\nEpoch: [29][0/782]\tTime 0.358 (0.358)\tData 0.322 (0.322)\tLoss 3.8915 (3.8915)\tAcc@1 68.750 (68.750)\tAcc@5 95.312 (95.312)\nEpoch: [29][100/782]\tTime 0.051 (0.053)\tData 0.002 (0.005)\tLoss 3.4755 (3.8441)\tAcc@1 67.188 (63.196)\tAcc@5 96.875 (89.527)\nEpoch: [29][200/782]\tTime 0.051 (0.052)\tData 0.002 (0.004)\tLoss 3.5425 (3.8937)\tAcc@1 68.750 (63.114)\tAcc@5 87.500 (89.560)\nEpoch: [29][300/782]\tTime 0.051 (0.052)\tData 0.002 (0.003)\tLoss 3.4693 (3.8759)\tAcc@1 70.312 (63.549)\tAcc@5 92.188 (89.530)\nEpoch: [29][400/782]\tTime 0.049 (0.051)\tData 0.002 (0.003)\tLoss 3.8305 (3.8908)\tAcc@1 65.625 (63.369)\tAcc@5 87.500 (89.327)\nEpoch: [29][500/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.6714 (3.9239)\tAcc@1 53.125 (63.021)\tAcc@5 84.375 (89.181)\nEpoch: [29][600/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.3722 (3.9334)\tAcc@1 65.625 (62.716)\tAcc@5 90.625 (89.133)\nEpoch: [29][700/782]\tTime 0.050 (0.051)\tData 0.003 (0.003)\tLoss 4.1921 (3.9484)\tAcc@1 71.875 (62.698)\tAcc@5 90.625 (89.058)\n * Acc@1 62.480 Acc@5 88.962\nepoch 29, total time 39.86\nTest: [0/313]\tTime 0.112 (0.112)\tLoss 2.5075 (2.5075)\tAcc@1 53.125 (53.125)\tAcc@5 78.125 (78.125)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 2.5518 (2.2826)\tAcc@1 50.000 (51.980)\tAcc@5 84.375 (80.910)\nTest: [200/313]\tTime 0.005 (0.006)\tLoss 1.9176 (2.2700)\tAcc@1 62.500 (51.570)\tAcc@5 81.250 (80.986)\nTest: [300/313]\tTime 0.005 (0.006)\tLoss 2.4885 (2.2576)\tAcc@1 46.875 (52.045)\tAcc@5 90.625 (80.866)\n * Acc@1 51.980 Acc@5 80.820\n==> training...\nEpoch: [30][0/782]\tTime 0.240 (0.240)\tData 0.202 (0.202)\tLoss 4.2030 (4.2030)\tAcc@1 56.250 (56.250)\tAcc@5 85.938 (85.938)\nEpoch: [30][100/782]\tTime 0.050 (0.053)\tData 0.002 (0.005)\tLoss 3.7367 (3.8871)\tAcc@1 53.125 (63.041)\tAcc@5 79.688 (88.970)\nEpoch: [30][200/782]\tTime 0.050 (0.052)\tData 0.002 (0.004)\tLoss 4.0680 (3.8708)\tAcc@1 59.375 (63.479)\tAcc@5 92.188 (89.241)\nEpoch: [30][300/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 4.1049 (3.8879)\tAcc@1 62.500 (63.081)\tAcc@5 87.500 (89.249)\nEpoch: [30][400/782]\tTime 0.049 (0.051)\tData 0.002 (0.003)\tLoss 3.7774 (3.9176)\tAcc@1 65.625 (63.018)\tAcc@5 93.750 (89.230)\nEpoch: [30][500/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 3.8912 (3.9321)\tAcc@1 65.625 (62.962)\tAcc@5 96.875 (89.197)\nEpoch: [30][600/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 5.1407 (3.9422)\tAcc@1 57.812 (62.807)\tAcc@5 85.938 (89.047)\nEpoch: [30][700/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 3.9212 (3.9432)\tAcc@1 67.188 (62.906)\tAcc@5 90.625 (89.007)\n * Acc@1 62.782 Acc@5 89.000\nepoch 30, total time 39.78\nTest: [0/313]\tTime 0.110 (0.110)\tLoss 2.4220 (2.4220)\tAcc@1 62.500 (62.500)\tAcc@5 84.375 (84.375)\nTest: [100/313]\tTime 0.006 (0.007)\tLoss 3.2339 (2.2525)\tAcc@1 37.500 (52.908)\tAcc@5 78.125 (82.488)\nTest: [200/313]\tTime 0.005 (0.006)\tLoss 1.6274 (2.2650)\tAcc@1 56.250 (52.488)\tAcc@5 90.625 (82.618)\nTest: [300/313]\tTime 0.008 (0.006)\tLoss 2.4749 (2.2790)\tAcc@1 43.750 (52.502)\tAcc@5 84.375 (82.454)\n * Acc@1 52.500 Acc@5 82.540\n==> training...\nEpoch: [31][0/782]\tTime 0.344 (0.344)\tData 0.301 (0.301)\tLoss 3.6851 (3.6851)\tAcc@1 59.375 (59.375)\tAcc@5 85.938 (85.938)\nEpoch: [31][100/782]\tTime 0.051 (0.053)\tData 0.002 (0.005)\tLoss 3.5506 (3.9093)\tAcc@1 68.750 (64.913)\tAcc@5 95.312 (89.171)\nEpoch: [31][200/782]\tTime 0.051 (0.052)\tData 0.002 (0.004)\tLoss 3.8349 (3.8918)\tAcc@1 65.625 (64.000)\tAcc@5 90.625 (89.187)\nEpoch: [31][300/782]\tTime 0.050 (0.052)\tData 0.002 (0.003)\tLoss 4.1422 (3.9236)\tAcc@1 64.062 (63.486)\tAcc@5 90.625 (89.120)\nEpoch: [31][400/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 3.7342 (3.9181)\tAcc@1 54.688 (63.186)\tAcc@5 89.062 (89.090)\nEpoch: [31][500/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 3.7608 (3.9374)\tAcc@1 60.938 (63.036)\tAcc@5 93.750 (89.041)\nEpoch: [31][600/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 3.9831 (3.9548)\tAcc@1 65.625 (62.708)\tAcc@5 85.938 (88.992)\nEpoch: [31][700/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 3.2588 (3.9560)\tAcc@1 75.000 (62.567)\tAcc@5 93.750 (88.996)\n * Acc@1 62.640 Acc@5 89.006\nepoch 31, total time 39.86\nTest: [0/313]\tTime 0.108 (0.108)\tLoss 2.7651 (2.7651)\tAcc@1 50.000 (50.000)\tAcc@5 78.125 (78.125)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 2.8540 (2.7053)\tAcc@1 53.125 (49.876)\tAcc@5 78.125 (79.425)\nTest: [200/313]\tTime 0.005 (0.006)\tLoss 2.4366 (2.6856)\tAcc@1 46.875 (49.922)\tAcc@5 81.250 (79.602)\nTest: [300/313]\tTime 0.005 (0.006)\tLoss 2.6558 (2.6843)\tAcc@1 43.750 (50.010)\tAcc@5 75.000 (79.662)\n * Acc@1 50.160 Acc@5 79.560\n==> training...\nEpoch: [32][0/782]\tTime 0.271 (0.271)\tData 0.199 (0.199)\tLoss 4.0630 (4.0630)\tAcc@1 57.812 (57.812)\tAcc@5 89.062 (89.062)\nEpoch: [32][100/782]\tTime 0.051 (0.053)\tData 0.002 (0.004)\tLoss 3.7822 (3.9204)\tAcc@1 67.188 (62.577)\tAcc@5 92.188 (89.233)\nEpoch: [32][200/782]\tTime 0.051 (0.052)\tData 0.002 (0.003)\tLoss 2.7986 (3.8925)\tAcc@1 79.688 (63.324)\tAcc@5 95.312 (89.381)\nEpoch: [32][300/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.1438 (3.9166)\tAcc@1 62.500 (62.889)\tAcc@5 85.938 (89.332)\nEpoch: [32][400/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.0297 (3.9432)\tAcc@1 59.375 (62.792)\tAcc@5 90.625 (89.168)\nEpoch: [32][500/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 3.7948 (3.9490)\tAcc@1 48.438 (62.625)\tAcc@5 81.250 (89.091)\nEpoch: [32][600/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 3.2540 (3.9496)\tAcc@1 78.125 (62.802)\tAcc@5 95.312 (89.143)\nEpoch: [32][700/782]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 4.8800 (3.9562)\tAcc@1 53.125 (62.765)\tAcc@5 92.188 (89.036)\n * Acc@1 62.796 Acc@5 89.030\nepoch 32, total time 39.81\nTest: [0/313]\tTime 0.106 (0.106)\tLoss 2.5657 (2.5657)\tAcc@1 43.750 (43.750)\tAcc@5 75.000 (75.000)\nTest: [100/313]\tTime 0.005 (0.006)\tLoss 1.7393 (2.1035)\tAcc@1 56.250 (54.332)\tAcc@5 90.625 (83.818)\nTest: [200/313]\tTime 0.006 (0.006)\tLoss 2.5518 (2.1249)\tAcc@1 56.250 (53.685)\tAcc@5 84.375 (83.738)\nTest: [300/313]\tTime 0.005 (0.006)\tLoss 3.2726 (2.1280)\tAcc@1 37.500 (53.821)\tAcc@5 84.375 (83.461)\n * Acc@1 53.780 Acc@5 83.440\n==> training...\nEpoch: [33][0/782]\tTime 0.269 (0.269)\tData 0.222 (0.222)\tLoss 4.3224 (4.3224)\tAcc@1 60.938 (60.938)\tAcc@5 92.188 (92.188)\nEpoch: [33][100/782]\tTime 0.051 (0.054)\tData 0.002 (0.005)\tLoss 3.5749 (3.8630)\tAcc@1 65.625 (62.531)\tAcc@5 93.750 (90.053)\nEpoch: [33][200/782]\tTime 0.050 (0.052)\tData 0.003 (0.004)\tLoss 4.3941 (3.8600)\tAcc@1 68.750 (62.974)\tAcc@5 90.625 (89.988)\nEpoch: [33][300/782]\tTime 0.050 (0.052)\tData 0.002 (0.003)\tLoss 4.8353 (3.8590)\tAcc@1 54.688 (63.144)\tAcc@5 82.812 (89.763)\nEpoch: [33][400/782]\tTime 0.050 (0.051)\tData 0.002 (0.003)\tLoss 3.5461 (3.8815)\tAcc@1 68.750 (63.112)\tAcc@5 89.062 (89.518)\n^C\nTraceback (most recent call last):\n  File \"/kaggle/working/RepDistiller/train_student.py\", line 376, in <module>\n    main()\n  File \"/kaggle/working/RepDistiller/train_student.py\", line 310, in main\n    train_acc, train_loss = train(epoch, train_loader, module_list, criterion_list, optimizer, opt)\n  File \"/kaggle/working/RepDistiller/helper/loops.py\", line 187, in train_distill\n    losses.update(loss.item(), input.size(0))\nKeyboardInterrupt\n","output_type":"stream"}],"execution_count":10}]}
